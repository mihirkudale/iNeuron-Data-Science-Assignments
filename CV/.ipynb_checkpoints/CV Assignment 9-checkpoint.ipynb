{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f10b11-8e8d-4a78-af31-42d3d40bacc8",
   "metadata": {},
   "source": [
    "# Assignment 9 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca5ec7-2617-47e1-a3af-73f92fe37038",
   "metadata": {},
   "source": [
    "**SUBMITTED BY: MIHIR KUDALE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc9408-5559-4ff8-a48f-55d579c5dd15",
   "metadata": {},
   "source": [
    "**1. What are the advantages of a CNN for image classification over a completely linked DNN?**\n",
    "\n",
    "**Ans:** The main advantage of a CNN for image classification over a fully connected DNN is that a CNN uses convolutional layers which are designed to extract features from images. These convolutional layers help to reduce the number of parameters that need to be trained, which increases the speed of training and reduces the chance of overfitting. Additionally, the convolutional layers can be used to detect patterns in images, which allows for the network to better recognize objects in the images. This improves accuracy and reduces the number of false positives that the network produces. Finally, CNNs are also more efficient with memory usage as they can learn to detect patterns in images with fewer parameters than a fully connected DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf961a-57d2-4a99-8e9f-a018d1f687ae",
   "metadata": {},
   "source": [
    "**2. Consider a CNN with three convolutional layers, each of which has three kernels, a stride of two,and SAME padding. The bottom layer generates 100 function maps, the middle layer 200, and the top layer 400. RGB images with a size of 200 x 300 pixels are used as input. How many criteria does\n",
    "the CNN have in total? How much RAM would this network need when making a single instance prediction if we're using 32-bit floats? What if you were to practice on a batch of 50 images?**\n",
    "\n",
    "**Ans:** The total number of criteria in this CNN is 23,400. For a single instance prediction, the network would need 1,872,000 bytes (approximately 1.8 MB) of RAM if using 32-bit floats. For a batch of 50 images, the network would need 93,600,000 bytes (approximately 93.6 MB) of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b3865-c7ad-441d-8cb5-e325efe1ce91",
   "metadata": {},
   "source": [
    "**3. What are five things you might do to fix the problem if your GPU runs out of memory while\n",
    "training a CNN?**\n",
    "\n",
    "**Ans:**\n",
    "1. Increase the batch size of the training data.\n",
    "2. Reduce the complexity of the network (e.g. number of layers, number of neurons per layer).\n",
    "3. Select a network architecture with lower memory requirements.\n",
    "4. Reduce the size of the input data.\n",
    "5. Reduce the number of training iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067d0d8-bb8d-4610-9219-287740894bbc",
   "metadata": {},
   "source": [
    "**4. Why would you use a max pooling layer instead with a convolutional layer of the same stride?**\n",
    "\n",
    "**Ans:** Max pooling layers are used to reduce the spatial size of an input representation, to reduce the number of parameters and computation in the network, and to make it invariant to small transformations. Max pooling layers are also used to control overfitting in the network. By using a max pooling layer with a convolutional layer of the same stride, the network can reduce the spatial size of the input representation and make it invariant to small translations, while still being able to detect important features in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5912c28-96d4-498c-9953-f9227b8c9679",
   "metadata": {},
   "source": [
    "**5. When would a local response normalization layer be useful?**\n",
    "\n",
    "**Ans:** Local response normalization layers are useful when training convolutional neural networks. This layer normalizes the responses of neurons in the same local receptive field, which helps reduce the overfitting of the model and allow for faster training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ddac2-64a7-4a2a-9291-4e56868bd2d1",
   "metadata": {},
   "source": [
    "**6. In comparison to LeNet-5, what are the main innovations in AlexNet? What about GoogLeNet and\n",
    "ResNets core innovations?**\n",
    "\n",
    "**Ans:** The main innovation in AlexNet is its use of ReLU activation function, dropout regularization, and data augmentation. It was also the first to use 8 layers and a large number of neurons.\n",
    "\n",
    "GoogLeNet introduced a new architecture, called Inception, which uses a combination of convolutional, pooling and fully-connected layers. It also uses a variety of inception modules to reduce the number of parameters and improve the accuracy of the model.\n",
    "\n",
    "ResNets core innovation is the use of residual learning. This approach uses skip connections which enable the model to learn the identity mapping, allowing it to learn even deeper networks. ResNets also uses batch normalization to improve the convergence of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347dae7-23e3-4cf3-9228-c6ef5ff60e82",
   "metadata": {},
   "source": [
    "**7. On MNIST, build your own CNN and strive to achieve the best possible accuracy.**\n",
    "\n",
    "**Ans:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c72e6de-e576-41e1-9d73-2d1a8e610462",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (28, 28),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (28, 28),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 60000,\n",
    "                         epochs = 2,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 10000)\n",
    "\n",
    "\n",
    "# Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/image.jpg', target_size = (28, 28))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'zero'\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 'one'\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 'two'\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 'three'\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 'four'\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 'five'\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 'six'\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 'seven'\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 'eight'\n",
    "else:\n",
    "    prediction = 'nine'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f7f33-9660-4667-a43d-93462e1688ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "94f538a246db0fa2df5e0015ac38ebae58f4075808dc245f921dd0fb55023058"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
